{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0MrEVoVmhOy"
      },
      "source": [
        "# Computer Vision Homework 3: Big vs Small Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0hnrUlYrGWS"
      },
      "source": [
        "## Brief"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_zuWZp5rSyN"
      },
      "source": [
        "Due date: Nov 13, 2023\n",
        "\n",
        "Required files: `homework-3.ipynb`, `report.pdf`\n",
        "\n",
        "To download the jupyter notebook from colab, you can refer to the colab tutorial we gave.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om7423NauKQ6"
      },
      "source": [
        "## Codes for Problem 1 and Problem 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX6pBqvV6RCq"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "73wanLwflUdb"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
        "from torchvision import transforms, models, datasets\n",
        "from tqdm import tqdm\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtXEq_Yx5j-L"
      },
      "source": [
        "### Check GPU Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Yz3wOsYwmEz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e48a414e-8a87-4159-ede7-61a924232a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using {device} device')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "zbpaGDdwnX9g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac1e6959-712f-4351-83c7-fa13b368d48f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-5c20ef1f-44cc-ffcf-fc6f-5a67e132a31f)\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAoPtdOR5ojk"
      },
      "source": [
        "### Set the Seed to Reproduce the Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Wphy638XBNj-"
      },
      "outputs": [],
      "source": [
        "def set_all_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "set_all_seed(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLmcH3NAH4wq"
      },
      "source": [
        "### Create Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "5VHp_O3_JgZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf243ac-171e-4c0e-8675-fc4c03840d42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "\n",
        "mean=(0.485, 0.456, 0.406)\n",
        "std=(0.229, 0.224, 0.225)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='data', train=True, download=True, transform=train_transform)\n",
        "valid_dataset = datasets.CIFAR10(root='data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
        "\n",
        "sixteenth_train_sampler = RandomSampler(train_dataset, num_samples=len(train_dataset)//16)\n",
        "half_train_sampler = RandomSampler(train_dataset, num_samples=len(train_dataset)//2)\n",
        "\n",
        "sixteenth_train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=sixteenth_train_sampler)\n",
        "half_train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=half_train_sampler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjFDtcWRnFS9"
      },
      "source": [
        "### Load Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "vgZV0CodnFS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30ae363-e9e6-4a65-c41b-78d0ba3a7662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        }
      ],
      "source": [
        "# HINT: Remember to change the model to 'resnet50' and the weights to weights=\"IMAGENET1K_V1\" when needed.\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', weights=None)\n",
        "\n",
        "# Background: The original resnet18 is designed for ImageNet dataset to predict 1000 classes.\n",
        "# TODO: Change the output of the model to 10 class.\n",
        "model.fc=nn.Linear(in_features=1920,out_features=10,bias=True)\n",
        "model=model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZo50knhnFS_"
      },
      "source": [
        "### Training and Testing Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "wlXKJeYWnFTA"
      },
      "outputs": [],
      "source": [
        "# TODO: Fill in the code cell according to the pytorch tutorial we gave.\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    num_batches = len(dataloader)\n",
        "    size = len(dataloader.dataset)\n",
        "    epoch_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for X, y in tqdm(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        pred = pred.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / num_batches\n",
        "    avg_acc = correct / size\n",
        "\n",
        "    return avg_epoch_loss, avg_acc\n",
        "def test(dataloader, model, loss_fn):\n",
        "    num_batches = len(dataloader)\n",
        "    size = len(dataloader.dataset)\n",
        "    epoch_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in tqdm(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            pred = model(X)\n",
        "\n",
        "            epoch_loss += loss_fn(pred, y).item()\n",
        "            pred = pred.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / num_batches\n",
        "    avg_acc = correct / size\n",
        "\n",
        "    return avg_epoch_loss, avg_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "az3bp4AgcmN_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iqBGAUm6b5W"
      },
      "source": [
        "## Codes for Problem 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5SBFMzPT6cP4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa28d3eb-958d-4213-87b3-0f43db409153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "100%|██████████| 196/196 [00:59<00:00,  3.27it/s]\n",
            "100%|██████████| 40/40 [00:08<00:00,  4.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1: Loss = 1.6303 Acc = 0.42 Test_Loss = 1.5806 Test_Acc = 0.46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [00:59<00:00,  3.32it/s]\n",
            "100%|██████████| 40/40 [00:08<00:00,  4.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  2: Loss = 1.2225 Acc = 0.56 Test_Loss = 1.2624 Test_Acc = 0.57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [00:59<00:00,  3.28it/s]\n",
            "100%|██████████| 40/40 [00:07<00:00,  5.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  3: Loss = 1.0367 Acc = 0.63 Test_Loss = 0.9990 Test_Acc = 0.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [00:59<00:00,  3.29it/s]\n",
            "100%|██████████| 40/40 [00:08<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  4: Loss = 0.9283 Acc = 0.67 Test_Loss = 0.9631 Test_Acc = 0.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [00:59<00:00,  3.30it/s]\n",
            "100%|██████████| 40/40 [00:07<00:00,  5.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  5: Loss = 0.8447 Acc = 0.70 Test_Loss = 0.8328 Test_Acc = 0.71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [00:59<00:00,  3.30it/s]\n",
            "100%|██████████| 40/40 [00:07<00:00,  5.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  6: Loss = 0.7734 Acc = 0.73 Test_Loss = 0.7749 Test_Acc = 0.73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [00:59<00:00,  3.28it/s]\n",
            "100%|██████████| 40/40 [00:07<00:00,  5.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  7: Loss = 0.7101 Acc = 0.75 Test_Loss = 0.7342 Test_Acc = 0.74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [00:59<00:00,  3.31it/s]\n",
            "100%|██████████| 40/40 [00:08<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  8: Loss = 0.6613 Acc = 0.77 Test_Loss = 0.7504 Test_Acc = 0.74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [00:59<00:00,  3.30it/s]\n",
            "100%|██████████| 40/40 [00:07<00:00,  5.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  9: Loss = 0.6322 Acc = 0.78 Test_Loss = 0.7296 Test_Acc = 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [00:59<00:00,  3.30it/s]\n",
            "100%|██████████| 40/40 [00:08<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Loss = 0.5931 Acc = 0.79 Test_Loss = 0.6488 Test_Acc = 0.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [01:00<00:00,  3.26it/s]\n",
            "100%|██████████| 40/40 [00:07<00:00,  5.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Loss = 0.5658 Acc = 0.80 Test_Loss = 0.6283 Test_Acc = 0.78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [00:59<00:00,  3.31it/s]\n",
            "100%|██████████| 40/40 [00:08<00:00,  4.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Loss = 0.5329 Acc = 0.81 Test_Loss = 0.6469 Test_Acc = 0.78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [00:59<00:00,  3.31it/s]\n",
            "100%|██████████| 40/40 [00:07<00:00,  5.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Loss = 0.5077 Acc = 0.82 Test_Loss = 0.6274 Test_Acc = 0.79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [00:59<00:00,  3.29it/s]\n",
            "100%|██████████| 40/40 [00:07<00:00,  5.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Loss = 0.4867 Acc = 0.83 Test_Loss = 0.6806 Test_Acc = 0.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [00:59<00:00,  3.30it/s]\n",
            "100%|██████████| 40/40 [00:07<00:00,  5.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Loss = 0.4765 Acc = 0.83 Test_Loss = 0.6179 Test_Acc = 0.79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [00:59<00:00,  3.30it/s]\n",
            "100%|██████████| 40/40 [00:07<00:00,  5.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Loss = 0.4437 Acc = 0.84 Test_Loss = 0.5786 Test_Acc = 0.80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [00:59<00:00,  3.31it/s]\n",
            "100%|██████████| 40/40 [00:07<00:00,  5.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: Loss = 0.4228 Acc = 0.85 Test_Loss = 0.6392 Test_Acc = 0.79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [01:00<00:00,  3.25it/s]\n",
            "100%|██████████| 40/40 [00:07<00:00,  5.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Loss = 0.4326 Acc = 0.85 Test_Loss = 0.6650 Test_Acc = 0.79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 196/196 [00:58<00:00,  3.32it/s]\n",
            "100%|██████████| 40/40 [00:07<00:00,  5.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Loss = 0.4034 Acc = 0.86 Test_Loss = 0.5438 Test_Acc = 0.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 146/196 [00:44<00:15,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-ceea8ffb1c44>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_densenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_densenet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_densenet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1:2d}: Loss = {train_loss:.4f} Acc = {train_acc:.2f} Test_Loss = {test_loss:.4f} Test_Acc = {test_acc:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-964a8c36131f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# TODO: Try to achieve the best performance given all training data using whatever model and training strategy.\n",
        "# (New) (You cannot use the model that was pretrained on CIFAR10)\n",
        "epochs_d = 100\n",
        "densenet_acc_plot = []\n",
        "densenet_test_acc_plot = []\n",
        "densenet_loss_plot = []\n",
        "densenet_test_loss_plot = []\n",
        "# HINT: Remember to change the model to 'resnet50' and the weights to weights=\"IMAGENET1K_V1\" when needed.\n",
        "model_densenet = torch.hub.load('pytorch/vision:v0.10.0', 'densenet201', weights=None)\n",
        "# Background: The original resnet18 is designed for ImageNet dataset to predict 1000 classes.\n",
        "# TODO: Change the output of the model to 10 class.\n",
        "model_densenet.fc=nn.Linear(in_features=1920,out_features=10,bias=True)\n",
        "model_densenet=model_densenet.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_densenet.parameters(), lr=1e-3)\n",
        "for epoch in range(epochs_d):\n",
        "    train_loss, train_acc = train(train_dataloader, model_densenet, loss_fn, optimizer)\n",
        "    test_loss, test_acc = test(valid_dataloader, model_densenet, loss_fn)\n",
        "    print(f\"Epoch {epoch + 1:2d}: Loss = {train_loss:.4f} Acc = {train_acc:.2f} Test_Loss = {test_loss:.4f} Test_Acc = {test_acc:.2f}\")\n",
        "    densenet_acc_plot.append(train_acc)\n",
        "    densenet_test_acc_plot.append(test_acc)\n",
        "    densenet_loss_plot.append(train_loss)\n",
        "    densenet_test_loss_plot.append(test_loss)\n",
        "print(\"Done!\")\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Accuracy\")\n",
        "plt.plot(densenet_acc_plot,label=\"densenet201 train acc\")\n",
        "plt.plot(densenet_test_acc_plot,label=\"test acc\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Loss\")\n",
        "plt.plot(densenet_loss_plot,label=\"densenet201 train loss\")\n",
        "plt.plot(densenet_test_loss_plot,label=\"test loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTSafuelpRYJ"
      },
      "source": [
        "## Problems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZctBdkurpQS"
      },
      "source": [
        "1. (30%) Finish the rest of the codes for Problem 1 and Problem 2 according to the hint. (2 code cells in total.)\n",
        "2. Train small model (resnet18) and big model (resnet50) from scratch on `sixteenth_train_dataloader`, `half_train_dataloader`, and `train_dataloader` respectively.\n",
        "3. (30%) Achieve the best performance given all training data using whatever model and training strategy.  \n",
        "  (You cannot use the model that was pretrained on CIFAR10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "786fQTdk0msC"
      },
      "source": [
        "## Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsd2yTmB0k5t"
      },
      "source": [
        "Write down your insights in the report. The file name should be report.pdf.\n",
        "For the following discussion, please present the results graphically as shown in Fig. 1 and discuss them.\n",
        "\n",
        "- (30%) The relationship between the accuracy, model size, and the training dataset size.  \n",
        "    (Total 6 models. Small model trains on the sixteenth, half, and all data. Big model trains on the sixteenth, half, and all data. If the result is different from Fig.1, please explain the possible reasons.)\n",
        "- (10%) What if we train the ResNet with ImageNet initialized weights (`weights=\"IMAGENET1K_V1\"`).\n",
        "Please explain why the relationship changed this way?\n",
        "\n",
        "Hint: You can try different hyperparameters combinations when training the models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWDxF-xIueMM"
      },
      "source": [
        "## Credits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sXpmSj2ufkh"
      },
      "source": [
        "1. [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MemcOLK_4ULJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}